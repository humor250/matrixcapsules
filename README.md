## ç”¨EMè·¯ç”±å®ç°çš„çŸ©é˜µèƒ¶å›Šï¼ˆä¸­æ–‡è¯‘æœ¬ï¼‰
        
Geoffrey Hinton, Sara Sabour, Nicholas Frosst{geoffhinton, sasabour, frosst}@google.com
è°·æ­Œå¤§è„‘   å¤šä¼¦å¤š, åŠ æ‹¿å¤§

### æ‘˜è¦
ä¸€ä¸ªèƒ¶å›Šæ˜¯ä¸€ç»„ç¥ç»å…ƒï¼Œå…¶è¾“å‡ºè¡¨å¾åŒä¸€å®ä½“çš„ä¸åŒå±æ€§ã€‚ä¸€ä¸ªèƒ¶å›Šç½‘ç»œçš„æ¯å±‚å«æœ‰å¤šä¸ªèƒ¶å›Šã€‚æˆ‘ä»¬æè¿°ä¸€ç§èƒ¶å›Šç‰ˆæœ¬ï¼Œå…¶ä¸­æ¯ä¸ªèƒ¶å›Šæœ‰ä¸€ä¸ªé€»è¾‘å•å…ƒæ¥è¡¨æ˜ä¸€ä¸ªå®ä½“çš„å­˜åœ¨æ€§å’Œä¸€ä¸ª4x4çŸ©é˜µï¼Œè¿™ä¸ªçŸ©é˜µèƒ½å¤Ÿä¹ å¾—è¡¨å¾é‚£ä¸ªå®ä½“ä¸è§‚å¯Ÿè€…ï¼ˆå§¿æ€ï¼‰çš„å…³ç³»ã€‚æ¯å±‚çš„ä¸€ä¸ªèƒ¶å›Šå¯¹ä¸Šå±‚çš„å¤šä¸ªä¸åŒèƒ¶å›Šæ„æˆçš„å§¿æ€çŸ©é˜µè¿›è¡ŒæŠ•ç¥¨ï¼Œæ–¹æ³•æ˜¯å®ƒçš„å§¿æ€çŸ©é˜µä¸å¯è®­ç»ƒçš„è§†ç‚¹ä¸å˜çš„èƒ½å¤Ÿä¹ å¾—è¡¨å¾å±€éƒ¨-æ•´ä½“å…³ç³»çš„å˜æ¢çŸ©é˜µç›¸ä¹˜ã€‚æ¯å¼ é€‰ç¥¨é€šè¿‡ä¸€ä¸ªåˆ†é…çš„ç³»æ•°è¿›è¡ŒåŠ æƒã€‚æ¯å¼ å›¾ç‰‡é‡‡ç”¨Expectation-Maximization algorithmå¯¹è¿™äº›ç³»æ•°è¿›è¡Œè¿­ä»£æ›´æ–°ï¼Œè¿™æ ·ï¼Œæ¯ä¸ªèƒ¶å›Šçš„è¾“å‡ºè·¯ç”±åˆ°æ¥å—ä¸€ç»„ç›¸ä¼¼é€‰ç¥¨çš„ä¸Šå±‚çš„ä¸€ä¸ªèƒ¶å›Šã€‚å˜æ¢çŸ©é˜µçš„è®­ç»ƒä¸åŒï¼Œæ˜¯åœ¨æ¯å¯¹ç›¸é‚»èƒ¶å›Šå±‚ä¹‹é—´é‡‡ç”¨å±•å¼€å¼è¿­ä»£çš„EMç®—æ³•ï¼ˆunrolled iterations of EMï¼‰è¿›è¡Œåå‘ä¼ æ’­ã€‚é€šè¿‡smallNORBè¯„æµ‹, ä¸æœ€å¥½è®°å½•ç›¸æ¯”ï¼Œèƒ¶å›Šå‡å°‘äº†45%çš„æµ‹è¯•é”™è¯¯ç‡ã€‚åŒæ—¶æ˜¾ç¤ºå‡ºæ¯”æ ‡å‡†çš„CNNå¯¹ç™½ç›’å¯¹æŠ—æ”»å‡»å…·æœ‰è¶…å¼ºçš„æŠµæŠ—åŠ›ã€‚

------
### 1 ç®€ä»‹
å·ç§¯ç¥ç»ç½‘ç»œæ˜¯æ„å»ºäºè¿™æ ·çš„ç®€å•äº‹å®ï¼Œå³ä¸€ä¸ªè§†è§‰ç³»ç»Ÿè¦å¯¹å›¾ç‰‡ä¸­çš„æ‰€ä»¥ä½ç½®é‡‡ç”¨åŒæ ·çš„çŸ¥è¯†ã€‚è¿™æ˜¯é€šè¿‡ç»‘å®šç‰¹å¾æ¢æµ‹å™¨çš„æƒé‡ï¼Œä»¥ä¾¿åœ¨ä¸€å¤„ä¹ å¾—çš„ç‰¹å¾åœ¨åˆ«å¤„æœ‰æ•ˆã€‚å·ç§¯èƒ¶å›Šç½‘ç»œæ‰©å±•ä½ç½®çŸ¥è¯†å…±äº«åˆ°åŒ…æ‹¬å±€éƒ¨-æ•´ä½“å…³ç³»çš„çŸ¥è¯†ï¼Œè¿™ç§å…³ç³»é€šè¿‡ä¸€ä¸ªç†Ÿæ‚‰çš„å›¾å½¢è¡¨ç¤ºã€‚è§†ç‚¹å˜åŒ–å¯¹åƒç´ å¼ºåº¦æœ‰å¤æ‚æ•ˆæœï¼Œä½†å¯¹è¡¨å¾å¯¹è±¡æˆ–å¯¹è±¡å±€éƒ¨å’Œè§‚å¯Ÿè€…ä¹‹é—´çš„å…³ç³»çš„å§¿æ€çŸ©é˜µæœ‰ç®€å•çº¿æ€§æ•ˆæœã€‚èƒ¶å›Šç½‘ç»œæ„å›¾åˆ©ç”¨å¥½è¿™ä¸€åº•å±‚çº¿æ€§å…³ç³»ï¼Œå¤„ç†è§†ç‚¹å˜åŒ–å’Œæå‡åˆ†å‰²å†³å®šåŠ›ã€‚èƒ¶å›Šç½‘ç»œåˆ©ç”¨é«˜ç»´åº¦å·§åˆè¿‡æ»¤ï¼šé€šè¿‡å¯»æ‰¾ç»™å§¿æ€çŸ©é˜µæŠ•ç¥¨çš„åè®®ï¼Œæ¢æµ‹å‡ºä¸€ä¸ªç†Ÿæ‚‰å¯¹è±¡ã€‚è¿™äº›ç¥¨æ¥è‡ªäºå·²ç»æ¢æµ‹å‡ºçš„å¯¹è±¡å±€éƒ¨ã€‚ä¸€ä¸ªå¯¹è±¡å±€éƒ¨äº§ç”Ÿä¸€ç¥¨ï¼Œæ–¹æ³•æ˜¯å®ƒçš„å§¿æ€çŸ©é˜µä¹˜ä»¥ä¸€ä¸ªä¹ å¾—çš„å˜æ¢çŸ©é˜µï¼Œå…¶è¡¨å¾è§†ç‚¹ä¸å˜çš„å±€éƒ¨å’Œæ•´ä½“å…³ç³»ã€‚éšç€è§†ç‚¹å˜åŒ–ï¼Œå±€éƒ¨å’Œæ•´ä½“çš„å§¿æ€çŸ©é˜µä¼šä»¥ä¸€ç§åè°ƒæ–¹å¼æ”¹å˜ï¼Œè¿™æ ·ï¼Œæ¥è‡ªä¸åŒå±€éƒ¨çš„æŠ•ç¥¨é—´çš„ä»»ä½•åè®®éƒ½ä¼šä¿æŒã€‚åœ¨ä¸€å †ä¸ç›¸å…³é€‰ç¥¨ä¸­å¯»æ‰¾é«˜ç»´é€‰ç¥¨çš„ç´§è‡´é›†ç¾¤æ˜¯ä¸€ç§è§£å†³å±€éƒ¨æ•´ä½“å½’å±é—®é¢˜çš„åŠæ³•ã€‚è¿™æ˜¯ä¸åŒå¯»å¸¸çš„ï¼Œå› ä¸ºæˆ‘ä»¬ä¸èƒ½ç”¨å¯¹ä½ç»´åº¦ç¿»è¯‘ç©ºé—´ç½‘æ ¼åŒ–ä»¥åˆ©å·ç§¯é‚£æ ·ï¼Œå¯¹é«˜ç»´åº¦ä½“æ€ç©ºé—´ç½‘æ ¼åŒ–ã€‚å¯¹äºè¿™ä¸ªæŒ‘æˆ˜ï¼Œæˆ‘ä»¬é‡‡ç”¨ç§°ä¸ºåè®®è·¯ç”±â€œroutingby-agreementâ€çš„å¿«é€Ÿè¿­ä»£å¤„ç†æ–¹æ³•ï¼Œå³å¯¹ä¸€ä¸ªå±€éƒ¨å±äºä¸€ä¸ªæ•´ä½“çš„æ¦‚ç‡è¿›è¡Œæ›´æ–°ï¼Œè¿™æ˜¯åŸºäºæ¥è‡ªäºé‚£ä¸ªå±€éƒ¨çš„é€‰ç¥¨æ¥è¿‘äºæ¥è‡ªå±äºé‚£ä¸ªæ•´ä½“çš„å…¶å®ƒå±€éƒ¨çš„é€‰ç¥¨ã€‚è¿™æ˜¯ä¸€ä¸ªå¼ºå¤§çš„åˆ†å‰²åŸåˆ™ï¼Œå…¶å…è®¸é‡‡ç”¨ç†Ÿæ‚‰çš„å›¾å½¢çŸ¥è¯†æ´¾ç”Ÿåˆ†å‰²ï¼Œè€Œä¸æ˜¯ä»…ä»…ä½¿ç”¨å¦‚é¢œè‰²æˆ–é€Ÿåº¦çš„è¿‘ä¼¼å€¼æˆ–ä¸€è‡´æ€§ç­‰ä½çº§æ–¹æ³•ã€‚èƒ¶å›Šç½‘ç»œå’Œæ ‡å‡†ç¥ç»ç½‘ç»œçš„ä¸€ä¸ªé‡è¦åŒºåˆ«åœ¨äºï¼Œä¸€ä¸ªèƒ¶å›Šçš„æ¿€æ´»æ˜¯åŸºäºä¸€ç§åœ¨å¤šä¸ªè¾“å…¥ä½“æ€é¢„æµ‹ä¹‹é—´çš„æ¯”è¾ƒï¼Œè€Œæ ‡å‡†ç¥ç»ç½‘ç»œæ˜¯åŸºäºåœ¨ä¸€ä¸ªå•ä¸€è¾“å…¥æ´»åŠ¨å‘é‡å’Œä¸€ä¸ªä¹ å¾—çš„æƒé‡å‘é‡çš„æ¯”è¾ƒã€‚

### 2 èƒ¶å›Šç½‘ç»œå¦‚ä½•å·¥ä½œ
å…¸å‹åœ°ï¼Œç¥ç»ç½‘ç»œåº”ç”¨ç®€å•çš„éçº¿æ€§ï¼Œå³åº”ç”¨ä¸€ä¸ªéçº¿æ€§å‡½æ•°è¿›è¡Œä¸€ä¸ªçº¿æ€§è¿‡æ»¤å™¨çš„æ ‡é‡è¾“å‡ºã€‚ä¹Ÿå¯ä»¥ç”¨softmaxçš„éçº¿æ€§å°†ä¸€ä¸ªå…¨éƒ¨logitså‘é‡è½¬åŒ–æˆä¸€ä¸ªæ¦‚ç‡å‘é‡ã€‚
èƒ¶å›Šç½‘ç»œç”¨ä¸€ä¸ªå¤æ‚å¾—å¤šçš„éçº¿æ€§æ–¹æ³•å°†ä¸€å±‚ä¸­çš„å…¨éƒ¨æ¿€æ´»æ¦‚ç‡å’Œèƒ¶å›Šå§¿æ€é›†åˆè½¬åŒ–ä¸ºä¸‹ä¸€å±‚çš„æ¿€æ´»æ¦‚ç‡å’Œèƒ¶å›Šå§¿æ€ã€‚ä¸€ä¸ªèƒ¶å›Šç½‘ç»œåŒ…å«å‡ ä¸ªèƒ¶å›Šå±‚ã€‚åœ¨Lå±‚çš„è¿™ç»„èƒ¶å›Šç”¨$â„¦_L$è¡¨ç¤ºã€‚æ¯ä¸ªèƒ¶å›Šæœ‰ä¸€ä¸ª4x4å§¿æ€çŸ©é˜µï¼ŒMï¼Œå’Œä¸€ä¸ªæ¿€æ´»æ¦‚ç‡ï¼Œaã€‚å®ƒä»¬å°±åƒä¸€ä¸ªæ ‡å‡†ç¥ç»ç½‘ç»œçš„æ´»åŠ¨ï¼šä¾èµ–äºå½“å‰è¾“å…¥ï¼Œä¸è¢«ä¿å­˜ã€‚åœ¨Lå±‚çš„æ¯ä¸ªèƒ¶å›Šiå’ŒL+1å±‚çš„æ¯ä¸ªèƒ¶å›Šjä¹‹é—´æœ‰ä¸€ä¸ª4x4çš„å¯è®­ç»ƒçš„è½¬æ¢çŸ©é˜µï¼Œ$W_{ij}$ã€‚è¿™äº›$ W_{ij} $ï¼ˆå’Œæ¯ä¸ªèƒ¶å›Šä¸¤ä¸ªä¹ å¾—çš„åç½®é¡¹ï¼‰æ˜¯å”¯ä¸€ä¿å­˜å‚æ•°ï¼Œè€Œä¸”å®ƒä»¬æ˜¯åˆ†åˆ«ä¹ å¾—çš„ã€‚èƒ¶å›Šiçš„å§¿æ€çŸ©é˜µç”±$W_{ij}$è¿›è¡Œå˜æ¢ï¼Œå³å¯¹èƒ¶å›Šjçš„å§¿æ€çŸ©é˜µæŠ•ä¸€ç¥¨$V_{ij} = M_iW_{ij}$ã€‚ä»¥$V_{ij}$ å’Œ $a_iï¼ˆi âˆˆ â„¦_L, j âˆˆ â„¦_{L+1}ï¼‰$ä¸ºè¾“å…¥ï¼Œç”¨éçº¿æ€§è·¯ç”±ç¨‹åºå¯¹L+1å±‚çš„å…¨éƒ¨èƒ¶å›Šçš„å§¿æ€å’Œæ¿€æ´»è¿›è¡Œè®¡ç®—ã€‚è¿™ä¸ªéçº¿æ€§ç¨‹åºæ˜¯EMç¨‹åºçš„ä¸€ä¸ªç‰ˆæœ¬ã€‚å®ƒè¿­ä»£åœ°è°ƒæ•´L+1å±‚èƒ¶å›Šçš„å‡å€¼ï¼Œå˜åŒ–å’Œæ¿€æ´»æ¦‚ç‡ï¼Œä»¥åŠåœ¨æ‰€æœ‰$i âˆˆ â„¦_L, j âˆˆ â„¦_{L+1}$ä¹‹é—´çš„åˆ†é…æ¦‚ç‡ã€‚åœ¨é™„å½•1ï¼Œæˆ‘ä»¬ç»™åè®®è·¯ç”±ï¼ˆrouting-by-agreementï¼‰ä¸€ä¸ªä¸­æ€§çš„ç›´è§‚ä»‹ç»ï¼Œå¹¶è¯¦ç»†æè¿°å®ƒä¸æ‹Ÿåˆé«˜æ–¯æ··åˆçš„EMç®—æ³•ä¹‹é—´çš„å…³ç³»ã€‚

### 3 ç”¨EMå®ç°è·¯ç”±åè®®
å‡å®šï¼Œæˆ‘ä»¬å·²ç»ç¡®å®šäº†ä¸€å±‚ä¸­æ‰€æœ‰èƒ¶å›Šçš„å§¿æ€å’Œæ¿€æ´»æ¦‚ç‡ï¼Œç°åœ¨ï¼Œæˆ‘ä»¬æƒ³è¦ç¡®å®šä¸Šå±‚æœ‰å“ªäº›æ¿€æ´»èƒ¶å›Šï¼Ÿä»¥åŠå¦‚ä½•å°†æ¯ä¸ªæ¿€æ´»çš„ä½å±‚èƒ¶å›Šåˆ†é…ç»™ä¸€ä¸ªæ¿€æ´»çš„é«˜å±‚èƒ¶å›Šã€‚é«˜å±‚ä¸­çš„æ¯ä¸ªèƒ¶å›Šå¯¹åº”ä¸€ä¸ªé«˜æ–¯ï¼ˆGaussianï¼‰ï¼Œä½å±‚ï¼ˆè½¬æˆäº†ä¸€ä¸ªå‘é‡ï¼‰çš„æ¯ä¸ªæ¿€æ´»èƒ¶å›Šçš„å§¿æ€å¯¹åº”ä¸€ä¸ªæ•°æ®ç‚¹ï¼ˆæˆ–è€…æ•°æ®ç‚¹çš„ç‰‡æ–­ï¼Œèƒ¶å›Šéƒ¨åˆ†æ¿€æ´»çš„æƒ…å†µä¸‹ï¼‰åˆ©ç”¨æœ€çŸ­æè¿°é•¿åº¦åŸåˆ™ï¼Œå½“å†³å®šæ˜¯å¦æ¿€æ´»ä¸€ä¸ªé«˜å±‚èƒ¶å›Šæ—¶ï¼Œæˆ‘ä»¬é¢ä¸´ä¸€ç§é€‰æ‹©ã€‚

é€‰æ‹©0: å¦‚æœä¸æ¿€æ´»å®ƒï¼Œè¦æè¿°æ‰€æœ‰åˆ†é…ç»™é«˜å±‚èƒ¶å›Šçš„ä½å±‚èƒ¶å›Šçš„å§¿æ€ï¼Œæˆ‘ä»¬å¿…é¡»ä¸ºæ¯ä¸ªæ•°æ®ç‚¹ä»˜å‡º$âˆ’Î²u$çš„å›ºå®šå¼€é”€ã€‚åœ¨éé€‚å½“å‡åŒ€å…ˆéªŒåˆ†å¸ƒçš„æƒ…å†µä¸‹ï¼Œè¿™ä¸ªå¼€é”€æ˜¯æ•°æ®ç‚¹çš„è´Ÿå¯¹æ•°æ¦‚ç‡å¯†åº¦ã€‚å¯¹äºç‰‡æ®µåˆ†é…ï¼Œæˆ‘ä»¬ä»˜å‡ºå›ºå®šå¼€é”€çš„ç‰‡æ®µã€‚

é€‰æ‹©1: å¦‚æœæ¿€æ´»æ›´é«˜çº§åˆ«çš„èƒ¶å›Šï¼Œæˆ‘ä»¬å¿…é¡»ä»˜å‡º$âˆ’Î²a$çš„å›ºå®šå¼€é”€æ¥ç¼–ç å®ƒçš„å‡å€¼å’Œæ–¹å·®ï¼Œä»¥åŠå®ƒæ˜¯æ¿€æ´»çš„äº‹å®ï¼Œç„¶åæ”¯ä»˜é¢å¤–çš„è´¹ç”¨ï¼Œå¹¶æŒ‰ç…§åˆ†é…æ¦‚ç‡è¿›è¡Œæ¯”ä¾‹åˆ†é…ï¼Œä»¥æè¿°è¾ƒä½çº§åˆ«çš„å‡å€¼å’Œé¢„æµ‹å€¼ä¹‹é—´çš„å·®å¼‚ï¼Œè¿™æ˜¯å½“æ›´é«˜çº§åˆ«èƒ¶å›Šçš„å‡å€¼é€šè¿‡è½¬æ¢çŸ©é˜µçš„é€†å‘æ–¹æ³•æ¥é¢„æµ‹å®ƒä»¬æ—¶éœ€è¦çš„ã€‚è®¡ç®—æè¿°ä¸€ä¸ªæ•°æ®ç‚¹æˆæœ¬çš„ç®€å•å¾—å¤šçš„æ–¹æ³•æ˜¯ï¼Œåœ¨æ— è®ºå½’å±å“ªä¸ªé«˜å±‚èƒ¶å›Šæ‹Ÿåˆçš„é«˜æ–¯åˆ†å¸ƒä¸‹ï¼Œä½¿ç”¨é‚£ä¸ªæ•°æ®ç‚¹çš„é€‰ç¥¨çš„è´Ÿå¯¹æ•°æ¦‚ç‡å¯†åº¦ã€‚

å¯¹äºé™„å½•1è§£é‡Šçš„ç†ç”±ï¼Œæ˜¯ä¸æ­£ç¡®çš„ï¼Œä¸è¿‡ï¼Œæˆ‘ä»¬ç”¨å®ƒæ˜¯å› ä¸ºå®ƒéœ€è¦æ›´å°‘çš„è®¡ç®—ï¼ˆåœ¨é™„å½•ä¸­ä¹Ÿæœ‰è¯´æ˜ï¼‰ã€‚
é€‰æ‹©0å’Œ1åœ¨å¼€é”€æ–¹é¢çš„åŒºåˆ«æ˜¯ï¼Œåœ¨æ¯æ¬¡è¿­ä»£ä¸­é€šè¿‡é€»è¾‘å‡½æ•°ç¡®å®šæ›´é«˜çº§åˆ«èƒ¶å›Šçš„æ¿€æ´»æ¦‚ç‡ã€‚é™„å½•1è§£é‡Šäº†é€»è¾‘å‡½æ•°æ˜¯æ­£ç¡®é€‰æ‹©çš„åŸå› ã€‚
ä½¿ç”¨æˆ‘ä»¬é’ˆå¯¹ä¸Šè¿°é€‰æ‹©1çš„é«˜æ•ˆè¿‘ä¼¼å€¼ï¼Œé€šè¿‡ä½¿ç”¨æœ‰è½´å¯¹é½åæ–¹å·®çŸ©é˜µçš„æ´»åŠ¨èƒ¶å›Šjæ¥è§£é‡Šæ•´ä¸ªæ•°æ®ç‚¹iäº§ç”Ÿçš„å¢é‡æˆæœ¬ï¼Œç®€å•åœ°è¯´ï¼Œå°±æ˜¯è§£é‡ŠæŠ•ç¥¨$V_{ij}$çš„æ¯ä¸ªç»´åº¦hçš„å…¨ç»´å¼€é”€æ€»å’Œã€‚ç®€å•æè¿°ä¸º$âˆ’ln(P^h_{i|j}) $ å…¶ä¸­ $P^h_{i|j}$æ˜¯çŸ¢é‡åŒ–é€‰ç¥¨$V_{ij}$çš„$h^{th}$ç»„ä»¶çš„æ¦‚ç‡å¯†åº¦ï¼Œè¿™æ˜¯åœ¨jå¯¹ç»´åº¦hçš„é«˜æ–¯æ¨¡å‹ä¸­ï¼Œæœ‰æ–¹å·®$(Ïƒ^h_j)^2$å’Œå‡å€¼$Âµ^h_j$ï¼Œå…¶ä¸­$Âµ_j$æ˜¯jçš„å§¿æ€çŸ©é˜µ$M_j$çš„çŸ¢é‡åŒ–ç‰ˆæœ¬ã€‚

$P^h_{i|j} = \frac{1}{\sqrt{2Ï€(Ïƒ^h_j)^2}}exp\Bigl(âˆ’\frac{(V^h_{ij} âˆ’ Âµ^h_j)^2}{2(Ïƒ^h_j)^2}\Bigr),
ln(P^h_{i|j}) = \frac{(V^h_{ij} âˆ’ Âµ^h_j)^2}{2(Ïƒ^h_j)^2} âˆ’ ln(Ïƒ^h_j) âˆ’ ln(2Ï€)/2$

å¯¹jçš„ä¸€ä¸ªå•ä¸ªç»´åº¦hï¼Œè®¡ç®—å…¶å…¨éƒ¨ä½å±‚èƒ¶å›Šçš„æ€»å’Œï¼Œå¾—åˆ°ï¼š

$$cost{^h_j} = \sum_iâˆ’r_{ij} ln(P^h_{i|j})$$

$$=\frac{\sum_ir_{ij} (V^h_{ij} âˆ’ Âµ^h_j)^2}{2(Ïƒ^h_j)^2}+(ln(Ïƒ^h_j) + \frac{ln(2Ï€)}2)\sum_ir_{ij}           (1)$$
$$= \biggl(ln(Ïƒ^h_j) + \frac{1+ln(2Ï€)}2\biggr) \sum_ir_{ij} $$

å…¶ä¸­$\sum_ir_{ij}$ æ˜¯åˆ†é…ç»™jçš„æ•°æ®é‡ï¼Œ$V^h_{ij}$æ˜¯$V_{ij}$åœ¨ç»´åº¦hä¸Šçš„å€¼ã€‚å¼€å¯èƒ¶å›Šjæé«˜äº†åˆ†é…ç»™jçš„è¾ƒä½çº§åˆ«èƒ¶å›Šå‡å€¼çš„æè¿°é•¿åº¦ï¼Œä»æ¯ä¸ªè¾ƒä½çº§åˆ«èƒ¶å›Šçš„$-Î²u$åˆ°$-Î²a$åŠ ä¸Šæ‰€æœ‰ç»´åº¦çš„æˆæœ¬æ€»å’Œï¼Œæ‰€ä»¥æˆ‘ä»¬å®šä¹‰èƒ¶å›Šjçš„æ¿€æ´»åŠŸèƒ½ä¸ºï¼š

$$a_j = logistic\biggl(Î»\bigl(Î²a âˆ’ Î²u\sum_ir_{ij} âˆ’\sum_hcost^h_j\bigr)\biggr) (2)$$

å…¶ä¸­ï¼Œ$Î²a$å¯¹äºæ‰€æœ‰èƒ¶å›Šè€Œè¨€æ˜¯ä¸€æ ·çš„ï¼Œè€Œä¸”ï¼Œ$Î»$æ˜¯ä¸€ä¸ªé€†å‘æ¸©åº¦å‚æ•°. æˆ‘ä»¬é€šè¿‡å·®å¼‚æ–¹æ³•å­¦ä¹ $Î²a$å’Œ$Î²u$ï¼Œå¹¶å°†$Î»$è®¾å®šä¸ºè¶…å‚æ•°ã€‚è¦å®ŒæˆL + 1å±‚èƒ¶å›Šçš„å§¿æ€å‚æ•°å’Œæ¿€æ´»ï¼Œæˆ‘ä»¬åœ¨Lå±‚å·²ç»å®Œæˆå§¿æ€å‚æ•°å’Œæ¿€æ´»ä¹‹åè¿è¡Œå‡ è½®EMç®—æ³•è¿­ä»£ï¼ˆé€šå¸¸ä¸º3è½®ï¼‰ã€‚ç”±æ•´ä¸ªèƒ¶å›Šå±‚å®ç°çš„éçº¿æ€§ç®—æ³•æ˜¯ä¸€ç§ä½¿ç”¨EMç®—æ³•çš„é›†ç¾¤å‘ç°å½¢å¼ï¼Œæ‰€ä»¥æˆ‘ä»¬ç§°ä¹‹ä¸ºEMè·¯ç”±ã€‚

----------

ç¨‹åº1è·¯ç”±ç®—æ³•è¿”å›å±‚L+1ä¸­çš„èƒ¶å›Šçš„æ¿€æ´»å’Œå§¿åŠ¿ï¼Œåœ¨ç»™å‡ºèƒ¶å›Šåœ¨å±‚Lä¸­çš„æ¿€æ´»å’ŒæŠ•ç¥¨æƒ…å†µä¸‹ã€‚$V^h_{ij}$æ˜¯æ¥è‡ªä»Lå±‚çš„æ¿€æ´»$a_i$èƒ¶å›Šiåˆ°L+1å±‚çš„èƒ¶å›Šjçš„ç¬¬hç»´é€‰ç¥¨. $Î²aï¼ŒÎ²u$æ˜¯åŒºåˆ«ä¹ å¾—çš„ï¼Œå¹¶ä¸”é€†å‘æ¸©åº¦Î»åœ¨æ¯æ¬¡è¿­ä»£ä¸­æŒ‰å›ºå®šæ—¶é—´è¡¨æé«˜ã€‚

----------
1: **procedure** EM ROUTING$(a, V )$

2: $âˆ€i âˆˆ â„¦_L, j âˆˆ â„¦_L+1: R_{ij} â† 1/|â„¦_L+1|$

3: for $t$ iterations do

4: $âˆ€j âˆˆ â„¦_L+1$: M-STEP$(a, R, V , j)$

5: $âˆ€i âˆˆ â„¦_L$: E-STEP$(Âµ, Ïƒ, a, V , i)$

return $a, M$


1: **procedure** M-STEP$(a, R, V , j)$ . ã€‹for one higher-level capsule, j

2: $âˆ€i âˆˆ â„¦_L: R_{ij} â† R_{ij} âˆ— a_i$

3: $âˆ€h: Âµ^h_j â†\frac{\sum_i R_{ij}V^h_{ij}}{\sum_i R_{ij}}$

4: $âˆ€h: (Ïƒ^h_j)^2 â†\frac{\sum_i Rij (V^h_{ij}âˆ’Âµ^h_j)^2}{\sum_i Rij}$

5: $cost^h â†\bigl(Î²u + log(Ïƒ^h_j)\bigr)\sum_i R_{ij}$

6: $a_j â† logistic(Î»(Î²_a âˆ’\sum_hcost^h))$


1: **procedure** E-STEP(Âµ, Ïƒ, a, V , i) . ã€‹for one lower-level capsule, i

2: $âˆ€j âˆˆ â„¦_{L+1}: p_j â† \frac{1}{\sqrt{\prod^H_h2Ï€(Ïƒ^h_j)2}}exp\bigl(âˆ’\sum^H_h\frac{(V^h_{ij}âˆ’Âµ^h_j)2}{2(Ïƒ^h_j)2}\bigr)$

3: $âˆ€j âˆˆ â„¦_{L+1}: R_{ij} â† \frac{a_j p_j}{\sum_{kâˆˆâ„¦_{L+1}}a_kp_k}$


### 4 èƒ¶å›Šç½‘ç»œæ¶æ„
æ¨¡å‹æ€»çš„æ¶æ„å¦‚å›¾1æ‰€ç¤ºã€‚
æ¨¡å‹ç”±ä¸€ä¸ª5x5å¸¦32é€šé“(A=32)ï¼Œç”¨ReLUéçº¿æ€§å‡½æ•°ï¼Œæ­¥é•¿ä¸º2çš„å·ç§¯å±‚å¼€å§‹ã€‚æ‰€æœ‰å…¶å®ƒå±‚æ˜¯èƒ¶å›Šå±‚ï¼Œå§‹äºä¸»èƒ¶å›Šå±‚ã€‚
B=32ä¸»èƒ¶å›Šç±»å‹çš„æ¯ä¸ªèƒ¶å›Šçš„4x4å§¿æ€æ˜¯ä¸€ä¸ªä¹ å¾—çš„æ‰€æœ‰çš„ä½å±‚çš„åœ¨é‚£ä¸ªä¸­å¿ƒweiReLUçš„çº¿æ€§è½¬æ¢ã€‚

![æ¶æ„å›¾](https://github.com/humor250/matrixcapsules/blob/master/cape.png)

å›¾1ï¼šèƒ¶å›Šç½‘ç»œæ¶æ„æœ‰ä¸€ä¸ªReLUå·ç§¯å±‚ï¼Œåé¢è·Ÿä¸€ä¸ªä¸»å·ç§¯èƒ¶å›Šå±‚å’Œä¸¤ä¸ªå…¶å®ƒå·ç§¯èƒ¶å›Šå±‚ã€‚

ä¸»èƒ¶å›Šçš„æ¿€æ´»æ˜¯åˆ©ç”¨sigmoidå‡½æ•°å¤„ç†åŒç»„çš„ä½å±‚ReLUçš„æƒé‡æ€»å’Œäº§ç”Ÿã€‚ä¸»èƒ¶å›Šä¹‹åæ˜¯ä¸¤ä¸ª3x3å·ç§¯èƒ¶å›Šå±‚ï¼ˆK = 3ï¼‰ï¼Œæ¯ä¸ªéƒ½æœ‰32ä¸ªèƒ¶å›Šç±»å‹ï¼ˆC = D = 32ï¼‰ï¼Œæ­¥å¹…åˆ†åˆ«ä¸º2å’Œ1ã€‚æœ€åä¸€å±‚å·ç§¯èƒ¶å›Šè¿æ¥åˆ°æ¯ä¸ªè¾“å‡ºçº§éƒ½æœ‰ä¸€ä¸ªèƒ¶å›Šçš„æœ€ç»ˆèƒ¶å›Šå±‚ã€‚å°†æœ€åä¸€ä¸ªå·ç§¯èƒ¶å›Šå±‚è¿æ¥åˆ°æœ€åä¸€å±‚æ—¶ï¼Œæˆ‘ä»¬ä¸æƒ³ä¸¢å¼ƒè¿œç¦»æœ‰å…³å·ç§¯èƒ¶å›Šä½ç½®çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬ä¹Ÿæƒ³åˆ©ç”¨æ‰€æœ‰åŒä¸€ç±»å‹çš„èƒ¶å›Šéƒ½åœ¨ä¸åŒä½ç½®æå–åŒä¸€ä¸ªå®ä½“çš„äº‹å®ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬åˆ†äº«åŒä¸€èƒ¶å›Šç±»å‹çš„ä¸åŒä½ç½®çš„å˜æ¢çŸ©é˜µï¼Œç„¶åå°†æ¯ä¸ªèƒ¶å›Šçš„æ¥å—åŸŸä¸­å¿ƒçš„ç¼©æ”¾åæ ‡ï¼ˆè¡Œï¼Œåˆ—ï¼‰æ·»åŠ åˆ°å®ƒçš„æŠ•ç¥¨çŸ©é˜µå³ä¾§æ ä¸­çš„å¤´ä¸¤ä¸ªå…ƒç´ ã€‚æˆ‘ä»¬ç§°è¿™ç§æŠ€æœ¯ä¸ºåæ ‡åŠ æˆã€‚è¿™åº”è¯¥æœ‰åŠ©äºè¿™ä¸ªå…±äº«çš„æœ€ç»ˆè½¬æ¢äº§ç”Ÿä»·å€¼ï¼Œå› ä¸ºè¿™ä¸¤ä¸ªå…ƒç´ è¡¨ç¤ºäº†è¿™ä¸ªç›¸å¯¹äºèƒ¶å›Šæ¥å—åŸŸä¸­å¿ƒçš„å®ä½“çš„ç²¾ç¡®ä½ç½®ã€‚

è·¯ç”±ç¨‹åºåœ¨æ¯å¯¹ç›¸é‚»çš„èƒ¶å›Šå±‚ä¹‹é—´ä½¿ç”¨ã€‚å¯¹äºå·ç§¯èƒ¶å›Šï¼ŒL+1å±‚çš„æ¯ä¸ªèƒ¶å›Šåªå°†åé¦ˆå‘é€åˆ°Lå±‚ä¸­å…¶æ¥å—åŸŸå†…çš„èƒ¶å›Šã€‚å› æ­¤ï¼ŒLå±‚çš„ä¸€ä¸ªèƒ¶å›Šçš„æ¯ä¸ªå·ç§¯å®ä¾‹ä»¥æœ€å¤§æ ¸å°ºå¯¸Xæ¥æ”¶æ¥è‡ªL+1å±‚çš„æ¯ä¸ªèƒ¶å›Šç±»å‹çš„æ ¸å°ºå¯¸åé¦ˆã€‚è¶Šæ¥è¿‘å›¾åƒè¾¹ç•Œçš„å®ä¾‹æ¥æ”¶è¾ƒå°‘çš„åé¦ˆï¼Œå¦‚è§’è½å®ä¾‹æ¥æ”¶ä»…ä¸€ä¸ªæ¥è‡ªL+1å±‚çš„ä¸€ä¸ªåé¦ˆã€‚

### 4.1 SPREAD LOSSä¼ æ’­æŸå¤±
In order to make the training less sensitive to the initialization and hyper-parameters of the model,
we use â€œspread lossâ€ to directly maximize the gap between the activation of the target class (at) and
the activation of the other classes. If the activation of a wrong class, ai
, is closer than the margin,
m, to at then it is penalized by the squared distance to the margin:
$Li = (max(0, m âˆ’ (a_t âˆ’ a_i))^2, L =\sum_{i \neq t}L_i (3)$
By starting with a small margin of 0.2 and linearly increasing it during training to 0.9, we avoid
dead capsules in the earlier layers. Spread loss is equivalent to squared Hinge loss with m = 1.
Guermeur & Monfrini (2011) studies a variant of this loss in the context of multi class SVMs.

ä¸ºäº†é™ä½è®­ç»ƒå¯¹æ¨¡å‹çš„åˆå§‹å‚æ•°å’Œè¶…å‚æ•°æ•æ„Ÿåº¦ï¼Œæˆ‘ä»¬ä½¿ç”¨â€œä¼ æ’­æŸå¤±â€æ¥ç›´æ¥æœ€å¤§åŒ–ç›®æ ‡ç±»ï¼ˆ$a_t$ï¼‰æ¿€æ´»å’Œå…¶ä»–ç±»æ¿€æ´»ä¹‹é—´çš„é—´è·ã€‚å¦‚æœé”™è¯¯ç±»åˆ«$a_i$çš„æ¿€æ´»æ¯”å¯¹$a_t$ä½™é‡mæ›´è¿‘ï¼Œé‚£ä¹ˆå®ƒçš„ç½šé¢æ˜¯è·ç¦»å¹³æ–¹ï¼š$$L_i = (max(0, m âˆ’ (a_t âˆ’ a_i))^2, L =\sum_{i \neq t}L_i (3)$$ ä»0.2çš„å°å¹…åº¦å¼€å§‹ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å°†å…¶çº¿æ€§å¢åŠ åˆ°0.9ï¼Œæˆ‘ä»¬é¿å…äº†æ—©æœŸå±‚ä¸­çš„æ­»èƒ¶å›Šã€‚ä¼ æ’­æŸå¤±ç›¸å½“äºm = 1æ—¶çš„HingeæŸå¤±å€¼çš„å¹³æ–¹ã€‚Guermeurï¼†Monfriniï¼ˆ 2011ï¼‰ç ”ç©¶äº†åœ¨å¤šç±»SVMèƒŒæ™¯ä¸‹è¿™ç§æŸå¤±çš„ä¸€ä¸ªå˜ä½“ã€‚

5 å®éªŒ

smallNORBæ•°æ®é›†ï¼ˆLeCun et al.ï¼ˆ2004ï¼‰ï¼‰æœ‰5ç§ç©å…·çš„ç°åº¦ç«‹ä½“å›¾åƒï¼šé£æœºï¼Œæ±½è½¦ï¼Œå¡è½¦ï¼Œäººç±»å’ŒåŠ¨ç‰©ï¼Œæ¯ç§æœ‰10ä¸ªæ¶‚å“‘å…‰ç»¿è‰²çš„ç‰©ç†å®ä¾‹ã€‚æ¯ç§çš„5ä¸ªç‰©ç†å®ä¾‹ä¸ºè®­ç»ƒæ•°æ®ï¼Œå¦å¤–5ä¸ªä¸ºæµ‹è¯•æ•°æ®ã€‚æ¯ä¸ªç©å…·éƒ½æœ‰18ä¸ªä¸åŒçš„æ–¹ä½è§’ï¼ˆ0-340ï¼‰ï¼Œ9ä¸ªé«˜åº¦å’Œ6ç§å…‰ç…§æ¡ä»¶ï¼Œæ‰€ä»¥è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†å‡åŒ…å«24,300ä¸ª96x96å›¾åƒçš„ç«‹ä½“å¯¹ã€‚æˆ‘ä»¬é€‰æ‹©smallNORBä½œä¸ºå¼€å‘èƒ¶å›Šç³»ç»Ÿçš„åŸºå‡†ï¼Œå› ä¸ºå®ƒæ˜¯ä¸“ä¸ºä¸€ç§çº¯ç²¹çš„å›¾å½¢è¯†åˆ«ä»»åŠ¡è€Œè¿›è¡Œçš„ç»†è‡´è®¾è®¡ï¼Œä¸å—ä¸Šä¸‹æ–‡å’Œé¢œè‰²å¹²æ‰°ï¼Œä½†å®ƒæ¯”MNISTæ›´æ¥è¿‘è‡ªç„¶å›¾åƒã€‚

è¡¨1ï¼šæˆ‘ä»¬çš„èƒ¶å›Šæ¶æ„çš„ä¸åŒç»„ä»¶å¯¹smallNORBçš„å½±å“ã€‚
![è¡¨ä¸€](https://github.com/humor250/matrixcapsules/blob/master/table1_matrixcapsules.png)

æˆ‘ä»¬å°†smallNORBç¼©å‡ä¸º48Ã—48åƒç´ ï¼Œæ¯å¹…å›¾åƒæ­£å¸¸åŒ–ä¸ºæœ‰é›¶å‡å€¼å’Œå•ä½å·®å¼‚ã€‚
åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éšæœºè£å‰ªå‡º32Ã—32å°å›¾ç‰‡å¹¶æ·»åŠ éšæœºäº®åº¦å’Œä¸è£å‰ªçš„å›¾åƒå½¢æˆå¯¹æ¯”ã€‚
åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä»å›¾åƒä¸­å¿ƒå‰ªä¸‹ä¸€ä¸ª32Ã—32çš„å°å›¾ç‰‡ï¼Œå¹¶åœ¨smallNORBä¸Šå®ç°1.8ï¼…çš„æµ‹è¯•é”™è¯¯ã€‚å¦‚æœæˆ‘ä»¬å¹³å‡åŒ–æµ‹è¯•æ—¶å¤šä¸ªè£å‰ªçš„ç§ç±»æ¿€æ´»ï¼Œæˆ‘ä»¬è¾¾åˆ°äº†1.4ï¼…ã€‚åœ¨ä¸ä½¿ç”¨å…ƒæ•°æ®çš„æƒ…å†µä¸‹ï¼ŒsmallNORBä¸Šæœ€å¥½çš„æŠ¥å‘Šç»“æœæ˜¯2.56ï¼…ï¼ˆCiresfortç­‰ï¼ˆ2011ï¼‰ï¼‰ã€‚ä¸ºäº†å®ç°è¿™ä¸€ç‚¹ï¼Œä»–ä»¬æ·»åŠ äº†ä¸¤ä¸ªé¢å¤–çš„ç«‹ä½“å›¾åƒå¯¹è¾“å…¥ï¼Œå›¾åƒæ˜¯é€šè¿‡ä¸­å¿ƒæ»¤æ³¢å™¨å’Œç¦»å¿ƒæ»¤æ³¢å™¨åˆ›å»ºçš„ã€‚ä»–ä»¬ä¹Ÿå¯¹å›¾åƒåº”ç”¨ä»¿å°„å¤±çœŸã€‚æˆ‘ä»¬çš„å·¥ä½œè¿˜å‡»è´¥äº†Sabourç­‰äººï¼ˆ2017ï¼‰åœ¨smallNORBä¸Šè¾¾åˆ°2.7ï¼…çš„èƒ¶å›Šç½‘ç»œå·¥ä½œã€‚æˆ‘ä»¬è¿˜åœ¨NORBä¸Šæµ‹è¯•äº†æˆ‘ä»¬çš„æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ä¸ªå¸¦å¢åŠ èƒŒæ™¯çš„smallNORBçš„ä¸€ä¸ªæŠ–åŠ¨ç‰ˆæœ¬ï¼Œæˆ‘ä»¬å®ç°äº†2.6ï¼…çš„é”™è¯¯ç‡ï¼Œçœ‹é½äº†2.7ï¼…çš„æœ€å¥½è®°å½•ï¼ˆCiresan et al.ï¼ˆ2012ï¼‰ï¼‰ã€‚

ä½œä¸ºæˆ‘ä»¬å¯¹æ–°è§†è§’è¿›è¡Œæ€»ç»“çš„å®éªŒåŸºå‡†ï¼Œæˆ‘ä»¬è®­ç»ƒäº†ä¸€ä¸ªCNNï¼Œå¸¦æœ‰ä¸¤ä¸ªåˆ†åˆ«å…·æœ‰32å’Œ64é€šé“çš„å·ç§¯å±‚ã€‚ä¸¤å±‚éƒ½æœ‰ä¸€ä¸ªå†…æ ¸å¤§å°
ä¸º5ï¼Œæ­¥å¹…ä¸º1ï¼Œå¸¦ä¸€ä¸ª2Ã—2æœ€å¤§åŒ–æ± ã€‚ç¬¬ä¸‰å±‚æ˜¯1024ä¸ªå•å…ƒçš„å¸¦ä¸¢å¤±ï¼ˆdropoutï¼‰çš„å…¨è¿æ¥å±‚ï¼Œå¹¶è¿æ¥åˆ°5è·¯softmaxè¾“å‡ºå±‚ã€‚æ‰€æœ‰éšè—çš„å•å…ƒä½¿ç”¨ReLU
éçº¿æ€§ç®—æ³•ã€‚å¯¹CNNåŸºå‡†ï¼Œæˆ‘ä»¬å‡†å¤‡äº†ä¸Šè¿°å¯¹èƒ¶å›Šç½‘ç»œç›¸åŒçš„å›¾ç‰‡ã€‚æˆ‘ä»¬çš„åŸºå‡†CNNæ˜¯å¹¿æ³›çš„è¶…å‚æœç´¢ï¼ˆè¿‡æ»¤å™¨å¤§å°ï¼Œé€šé“æ•°é‡å’Œå­¦ä¹ ç‡ï¼‰çš„ç»“æœã€‚
CNNåŸºå‡†åœ¨smallNORBä¸Šè¾¾åˆ°5.2ï¼…çš„æµ‹è¯•é”™è¯¯ç‡ï¼Œæœ‰4.2Må‚æ•°é‡ã€‚æˆ‘ä»¬æ¨æ–­Ciresfortç­‰äººï¼ˆ2011ï¼‰ç½‘ç»œæ‹¥æœ‰2.7Må‚æ•°ã€‚é€šè¿‡ä½¿ç”¨å°çŸ©é˜µä¹˜æ³•ï¼Œä¸åŸºå‡†CNNç›¸æ¯”ï¼Œæˆ‘ä»¬å°†å‚æ•°æ•°é‡å‡å°‘äº†15åˆ°310Kï¼ˆå’ŒCiresfortç­‰äººï¼ˆ2011ï¼‰çš„9å€å› å­ï¼‰ã€‚ ä¸€ä¸ªåªæœ‰68Kå¯è®­ç»ƒå‚æ•°çš„A=64ï¼ŒB=8ï¼ŒC=D=16çš„å°èƒ¶å›Šç½‘ç»œï¼Œè¾¾åˆ°äº†2.2ï¼…çš„æµ‹è¯•é”™è¯¯ç‡ï¼Œè¿™ä¹Ÿå‡»è´¥äº†ä¹‹å‰çš„æœ€ä¼˜çš„æµ‹è¯•é”™è¯¯ç‡ã€‚

Fig. 2 shows how EM routing adjusts the vote assignments and the capsule means to find the tight
clusters in the votes. 
The histograms show the distribution of vote distances to the mean (pose) of
each class capsule during routing iterations. 

At the first iteration, votes are distributed equally between
5 final layer capsules. Therefore, all capsules receive votes closer than 0.05 to their calculated
mean. In the second iteration, the assignment probability for agreeing votes increases. Therefore,
most of the votes are assigned to the detected clusters, the animal and human class in the middle
row, and the other capsules only receive scattered votes which are further than 0.05 from the calculated
mean. The zoomed-out version of Fig. 2 in the Appendix shows the full distribution of vote
distances at each routing iteration.
Instead of using our MDL-derived capsule activation term which computes a separate activation
probability per capsule, we could view the capsule activations like the mixing proportions in a
mixture of Gaussians and set them to be proportional to the sum of the assignment probabilities
of a capsule and to sum to 1 over all the capsules in a layer. This increases the test error rate on

å›¾2 æ˜¾ç¤ºäº†EMè·¯ç”±å¦‚ä½•è°ƒæ•´æŠ•ç¥¨åˆ†é…å’Œèƒ¶å›Šå‡å€¼ï¼Œä»¥æ‰¾åˆ°é€‰ç¥¨ä¸­çš„å¯†é›†ç¾¤ã€‚
ç›´æ–¹å›¾æ˜¾ç¤ºæŠ•ç¥¨è·ç¦»çš„å‡å€¼ï¼ˆå§¿æ€ï¼‰åˆ†å¸ƒåœ¨è·¯ç”±è¿­ä»£æœŸé—´æ¯ä¸ªåˆ†ç±»èƒ¶å›Šã€‚åœ¨ç¬¬ä¸€æ¬¡è¿­ä»£ä¸­ï¼ŒæŠ•ç¥¨ä¹‹é—´å¹³å‡åˆ†é…5æœ€åä¸€å±‚èƒ¶å›Šã€‚å› æ­¤ï¼Œæ‰€æœ‰èƒ¶å›Šçš„è®¡ç®—ç»“æœéƒ½ä¼šå¾—åˆ°æ¥è¿‘0.05çš„é€‰ç¥¨æ„æ€ã€‚åœ¨ç¬¬äºŒæ¬¡è¿­ä»£ä¸­ï¼ŒåŒæ„æŠ•ç¥¨çš„åˆ†é…æ¦‚ç‡å¢åŠ ã€‚å› æ­¤ï¼Œå¤§å¤šæ•°é€‰ç¥¨éƒ½è¢«åˆ†é…åˆ°æ£€æµ‹åˆ°çš„é›†ç¾¤ï¼Œä¸­é—´æ˜¯åŠ¨ç‰©å’Œäººç±»æ’ï¼Œè€Œå…¶ä»–èƒ¶å›Šåªèƒ½å¾—åˆ°æ¯”è®¡ç®—ç»“æœæ›´å¤šçš„é›¶æ•£æŠ•ç¥¨æ„æ€ã€‚é™„å½•ä¸­å›¾2çš„ç¼©å°ç‰ˆæ˜¾ç¤ºäº†æŠ•ç¥¨çš„å®Œæ•´åˆ†é…æ¯æ¬¡è·¯ç”±è¿­ä»£çš„è·ç¦»ã€‚è€Œä¸æ˜¯ä½¿ç”¨æˆ‘ä»¬çš„MDLæ´¾ç”Ÿçš„èƒ¶å›Šæ¿€æ´»æœ¯è¯­æ¥è®¡ç®—å•ç‹¬çš„æ¿€æ´»æ¯ä¸ªèƒ¶å›Šçš„æ¦‚ç‡ï¼Œæˆ‘ä»¬å¯ä»¥è§‚å¯Ÿèƒ¶å›Šæ¿€æ´»ï¼Œå¦‚aä¸­çš„æ··åˆæ¯”ä¾‹é«˜æ–¯æ··åˆï¼Œå¹¶å°†å®ƒä»¬è®¾ç½®ä¸ºä¸åˆ†é…æ¦‚ç‡çš„æ€»å’Œæˆæ¯”ä¾‹
çš„èƒ¶å›Šï¼Œå¹¶ä¸”åœ¨ä¸€å±‚ä¸­çš„æ‰€æœ‰èƒ¶å›Šä¸Šæ€»è®¡ä¸º1ã€‚è¿™å¢åŠ äº†æµ‹è¯•é”™è¯¯ç‡

![å›¾2](https://github.com/humor250/matrixcapsules/blob/master/pic2_matrixcapsules.png)
Figure 2: Histogram of distances of votes to the mean of each of the 5 final capsules after each
routing iteration. Each distance point is weighted by its assignment probability. All three images
are selected from the smallNORB test set. The routing procedure correctly routes the votes in the
truck and the human example. The plane example shows a rare failure case of the model where the
plane is confused with a car in the third routing iteration. The histograms are zoomed-in to visualize
only votes with distances less than 0.05. Fig. B.2 shows the complete histograms for the â€humanâ€
capsule without clipping the x-axis or fixing the scale of the y-axis.

å›¾2ï¼šæŠ•ç¥¨è·ç¦»æ¯ä¸ªèƒ¶å›Š5ä¸ªèƒ¶å›Šåå‡å€¼çš„ç›´æ–¹å›¾è·¯ç”±è¿­ä»£ã€‚ æ¯ä¸ªè·ç¦»ç‚¹ç”±å…¶åˆ†é…æ¦‚ç‡åŠ æƒã€‚ æ‰€æœ‰ä¸‰ä¸ªå›¾åƒæ˜¯ä»smallNORBæµ‹è¯•é›†ä¸­é€‰æ‹©çš„ã€‚ è·¯ç”±ç¨‹åºæ­£ç¡®è·¯ç”±ä¸­çš„æŠ•ç¥¨å¡è½¦å’Œäººçš„ä¾‹å­ã€‚è¯¥å¹³é¢ç¤ºä¾‹æ˜¾ç¤ºäº†ä¸€ä¸ªç½•è§çš„æ¨¡å‹å¤±è´¥æ¡ˆä¾‹é£æœºåœ¨ç¬¬ä¸‰æ¬¡è·¯çº¿è¿­ä»£ä¸­ä¸æ±½è½¦æ··æ·†ã€‚ç›´æ–¹å›¾è¢«æ”¾å¤§ä»¥å¯è§†åŒ–åªæœ‰è·ç¦»å°äº0.05çš„é€‰ç¥¨ã€‚å›¾B.2æ˜¾äº†â€œäººâ€çš„å®Œæ•´ç›´æ–¹å›¾ï¼Œèƒ¶å›Šæ²¡æœ‰å‰ªè£xè½´æˆ–å›ºå®šyè½´çš„æ¯”ä¾‹ã€‚

Table 2: A comparison of the smallNORB test error rate of the baseline CNN and the capsules model
on novel viewpoints when both models are matched on error rate for familiar viewpoints.

è¡¨2ï¼šåœ¨ç†Ÿæ‚‰è§†è§’ä¸‹ä¸¤æ¨¡å‹è¯¯å·®ç‡ç›¸åŒæ—¶ï¼Œæ–°è§†è§’ä¸‹åŸºçº¿CNNå’Œèƒ¶å›Šæ¨¡å‹çš„smalNORBæµ‹è¯•é”™è¯¯ç‡çš„æ¯”è¾ƒ
![è¡¨2](https://github.com/humor250/matrixcapsules/blob/master/table2_matrixcapsules.png)

smallNORB to 4.5%. Tab. 1 summarizes the effects of the number of routing iterations, the type of
loss, and the use of matrices rather than vectors for the poses.
The same capsules architecture as Fig. 1 achieves 0.44% test error rate on MNIST. If the number
of channels in the first hidden layer is increased to 256, it achieves 11.9% test error rate on Cifar10
(Krizhevsky & Hinton (2009)).

smallNORBé™è‡³4.5ï¼…ã€‚ æ ‡ç­¾.1ç»Ÿè®¡äº†è·¯ç”±è¿­ä»£æ¬¡æ•°çš„å½±å“ï¼Œå³ç±»å‹æŸå¤±ï¼Œä»¥åŠä½¿ç”¨çŸ©é˜µè€Œä¸æ˜¯å‘é‡æ¥è¡¨ç¤ºå§¿åŠ¿ã€‚ä¸å›¾1ç›¸åŒçš„èƒ¶å›Šæ¶æ„åœ¨MNISTä¸Šè¾¾åˆ°äº†0.44ï¼…çš„æµ‹è¯•é”™è¯¯ç‡ã€‚ å¦‚æœåœ¨ç¬¬ä¸€éšå±‚çš„é€šé“æ•°é‡å¢åŠ åˆ°256ä¸ªï¼Œåœ¨Cifar10ä¸Šå®ç°äº†11.9ï¼…çš„æµ‹è¯•é”™è¯¯ç‡ï¼ˆKrizhevskyï¼†Hintonï¼ˆ2009ï¼‰ï¼‰ã€‚

5.1 GENERALIZATION TO NOVEL VIEWPOINTS
A more severe test of generalization is to use a limited range of viewpoints for training and to test on
a much wider range. We trained both our convolutional baseline and our capsule model on one-third
of the training data containing azimuths of (300, 320, 340, 0, 20, 40) and tested on the two-thirds of
the test data that contained azimuths from 60 to 280. In a separate experiment, we trained on the 3
smaller elevations and tested on the 6 larger elevations.
It is hard to decide if the capsules model is better at generalizing to novel viewpoints because it
achieves better test accuracy on all viewpoints. To eliminate this confounding factor, we stopped
training the capsule model when its performance matched the baseline CNN on the third of the
test set that used the training viewpoints. Then, we compared these matched models on the twothirds
of the test set with novel viewpoints. Results in Tab. 2 show that compared with the baseline
CNN capsules with matched performance on familiar viewpoints reduce the test error rate on novel
viewpoints by about 30% for both novel azimuths and novel elevations.

5.1æ–°è§†è§’æ¦‚è¿°
æ›´ä¸¥æ ¼çš„æ€»çš„æµ‹è¯•æ˜¯ä½¿ç”¨æœ‰é™èŒƒå›´çš„è§‚ç‚¹è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•èŒƒå›´æ›´å¹¿æ³›ã€‚æˆ‘ä»¬å¯¹å·ç§¯åŸºçº¿å’Œèƒ¶å›Šæ¨¡å‹è¿›è¡Œäº†ä¸‰åˆ†ä¹‹ä¸€çš„è®­ç»ƒçš„è®­ç»ƒæ•°æ®åŒ…å«æ–¹ä½è§’ï¼ˆ300,320,340,0,20,40ï¼‰ï¼Œå¹¶åœ¨ä¸‰åˆ†ä¹‹äºŒçš„åŒ…å«æ–¹ä½è§’ä»60åˆ°280çš„æµ‹è¯•æ•°æ®ã€‚åœ¨å¦ä¸€ä¸ªå®éªŒä¸­ï¼Œæˆ‘ä»¬å¯¹3è¿›è¡Œäº†è®­ç»ƒè¾ƒå°çš„æµ·æ‹”é«˜åº¦å’Œ6ä¸ªè¾ƒå¤§çš„æµ·æ‹”é«˜åº¦è¿›è¡Œæµ‹è¯•ã€‚å¾ˆéš¾å†³å®šèƒ¶å›Šæ¨¡å‹æ˜¯å¦æ›´å¥½åœ°æ¨å¹¿åˆ°æ–°é¢–çš„è§‚ç‚¹ï¼Œå› ä¸ºå®ƒåœ¨æ‰€æœ‰è§†ç‚¹ä¸Šå®ç°æ›´å¥½çš„æµ‹è¯•å‡†ç¡®æ€§ã€‚ä¸ºäº†æ¶ˆé™¤è¿™ä¸ªæ··æ‚å› ç´ ï¼Œæˆ‘ä»¬åœäº†ä¸‹æ¥è®­ç»ƒèƒ¶å›Šæ¨¡å‹æ—¶ï¼Œå…¶æ€§èƒ½ä¸åŸºçº¿CNNçš„ä¸‰åˆ†ä¹‹ä¸€ç›¸ç¬¦æµ‹è¯•é›†ä½¿ç”¨äº†åŸ¹è®­è§‚ç‚¹ã€‚ç„¶åï¼Œæˆ‘ä»¬å°†è¿™äº›åŒ¹é…çš„æ¨¡å‹åœ¨ä¸¤ä¸‰ä½è¿›è¡Œæ¯”è¾ƒå…·æœ‰æ–°é¢–è§‚ç‚¹çš„æµ‹è¯•é›†ã€‚ç»“æœåœ¨Tab.2æ˜¾ç¤ºä¸åŸºçº¿ç›¸æ¯”,åœ¨ç†Ÿæ‚‰çš„è§†ç‚¹ä¸Šå…·æœ‰åŒ¹é…æ€§èƒ½çš„CNNèƒ¶å›Šï¼Œåœ¨æ–°è§†è§’ï¼Œå¯¹äºæ–°æ–¹ä½è§’å’Œæ–°é«˜ç¨‹ï¼Œå‡å°‘äº†çº¦ä¸º30ï¼…æµ‹è¯•é”™è¯¯ç‡ã€‚

6 ADVERSARIAL ROBUSTNESS
There is growing interest in the vulnerability of neural networks to adversarial examples; inputs
that have been slightly changed by an attacker to trick a neural net classifier into making the wrong
classification. These inputs can be created in a variety of ways, but straightforward strategies such as
FGSM (Goodfellow et al. (2014)) have been shown to drastically decrease accuracy in convolutional
neural networks on image classification tasks. We compare our capsule model and a traditional
convolutional model on their ability to withstand such attacks.
FGSM computes the gradient of the loss w.r.t. each pixel intensity and then changes the pixel
intensity by a fixed amount  in the direction that increases the loss. So the changes only depend on
the sign of the gradient at each pixel. This can be extended to a targeted attack by updating the input
to maximize the classification probability of a particular wrong class. We generated adversarial
attacks using FGSM because it has only one hyper-parameter and it is easy to compare models
that have very different gradient magnitudes. To test the robustness of our model, we generated
adversarial images from the test set using a fully trained model. We then reported the accuracy of
the model on these images.
We found that our model is significantly less vulnerable to both general and targeted FGSM adversarial
attacks; a small  can be used to reduce a convolutional modelâ€™s accuracy much more than an
equivalent  can on the capsule model (Fig. 3). It should also be noted that the capsule modelâ€™s accuracy
after the untargeted attack never drops below chance (20%) whereas the convolutional modelâ€™s
accuracy is reduced to significantly below chance with an  as small as 0.2.
We also tested our model on the slightly more sophisticated adversarial attack of the Basic Iterative
Method (Kurakin et al. (2016)), which is simply the aforementioned attack except it takes multiple
smaller steps when creating the adversarial image. Here too we find that our model is much more
robust to the attack than the traditional convolutional model.

6 æŠµå¾¡çš„é²æ£’æ€§
äººä»¬è¶Šæ¥è¶Šæ„Ÿå…´è¶£çš„æ˜¯ç¥ç»ç½‘ç»œå¯¹æ•Œå¯¹çš„ä¾‹å­ã€‚è¾“å…¥
æ”»å‡»è€…å·²ç»ç¨å¾®æ”¹å˜äº†è¿™ä¸€ç‚¹ï¼Œä»¥æ¬ºéª—ç¥ç»ç½‘ç»œåˆ†ç±»å™¨åˆ¶é€ é”™è¯¯
åˆ†ç±»ã€‚è¿™äº›è¾“å…¥å¯ä»¥é€šè¿‡å„ç§æ–¹å¼åˆ›å»ºï¼Œä½†ç›´æ¥çš„ç­–ç•¥å¦‚
FGSMï¼ˆGoodfellow et alã€‚ï¼ˆ2014ï¼‰ï¼‰å·²ç»æ˜¾ç¤ºå¤§å¤§é™ä½äº†å·ç§¯çš„å‡†ç¡®æ€§
ç¥ç»ç½‘ç»œå¯¹å›¾åƒåˆ†ç±»ä»»åŠ¡ã€‚æˆ‘ä»¬æ¯”è¾ƒæˆ‘ä»¬çš„èƒ¶å›Šæ¨¡å‹å’Œä¼ ç»Ÿæ¨¡å‹
å·ç§¯æ¨¡å‹å¯¹å…¶æŠµå¾¡è¿™ç§æ”»å‡»çš„èƒ½åŠ›ã€‚
FGSMè®¡ç®—æŸå¤±w.r.tçš„æ¢¯åº¦ã€‚æ¯ä¸ªåƒç´ çš„äº®åº¦ç„¶åæ”¹å˜åƒç´ 
å¼ºåº¦æŒ‰å›ºå®šé‡è®¡ç®—ï¼Ÿåœ¨å¢åŠ æŸå¤±çš„æ–¹å‘ä¸Šã€‚æ‰€ä»¥è¿™äº›å˜åŒ–åªä¾èµ–äº
æ¯ä¸ªåƒç´ å¤„æ¸å˜çš„ç¬¦å·ã€‚è¿™å¯ä»¥é€šè¿‡æ›´æ–°è¾“å…¥æ‰©å±•åˆ°æœ‰é’ˆå¯¹æ€§çš„æ”»å‡»
ä»¥æœ€å¤§åŒ–ç‰¹å®šé”™è¯¯ç±»åˆ«çš„åˆ†ç±»æ¦‚ç‡ã€‚æˆ‘ä»¬äº§ç”Ÿäº†æ•Œå¯¹æƒ…ç»ª
ä½¿ç”¨FGSMçš„æ”»å‡»ï¼Œå› ä¸ºå®ƒåªæœ‰ä¸€ä¸ªè¶…å‚æ•°ï¼Œå¹¶ä¸”å¾ˆå®¹æ˜“æ¯”è¾ƒæ¨¡å‹
å®ƒä»¬å…·æœ‰éå¸¸ä¸åŒçš„æ¢¯åº¦å¤§å°ã€‚ä¸ºäº†æµ‹è¯•æˆ‘ä»¬çš„æ¨¡å‹çš„é²æ£’æ€§ï¼Œæˆ‘ä»¬ç”Ÿæˆäº†
ä½¿ç”¨å®Œå…¨è®­ç»ƒçš„æ¨¡å‹ä»æµ‹è¯•é›†ä¸­è·å¾—æ•Œå¯¹å›¾åƒã€‚ç„¶åæˆ‘ä»¬æŠ¥å‘Šäº†å‡†ç¡®æ€§
è¿™äº›å›¾åƒä¸Šçš„æ¨¡å‹ã€‚
æˆ‘ä»¬å‘ç°æˆ‘ä»¬çš„æ¨¡å‹å¯¹äºæ™®é€šå’Œæœ‰é’ˆå¯¹æ€§çš„FGSMæ•Œæ‰‹éƒ½ä¸é‚£ä¹ˆè„†å¼±
æ”»å‡»;ä¸€ä¸ªå°çš„ ï¼Ÿå¯ä»¥ç”¨æ¥å‡å°‘å·ç§¯æ¨¡å‹çš„ç²¾åº¦è¿œè¿œè¶…è¿‡ä¸€ä¸ª
ç›¸å½“äºï¼Ÿå¯ä»¥åœ¨èƒ¶å›Šæ¨¡å‹ä¸Šï¼ˆå›¾3ï¼‰ã€‚è¿˜åº”è¯¥æŒ‡å‡ºï¼Œèƒ¶å›Šæ¨¡å‹çš„å‡†ç¡®æ€§
åœ¨éç›®æ ‡æ”»å‡»ä¹‹åæ°¸è¿œä¸ä¼šä½äºæœºä¼šï¼ˆ20ï¼…ï¼‰è€Œå·ç§¯æ¨¡å‹
å‡†ç¡®æ€§è¢«é™ä½åˆ°æ˜¾ç€ä½äºä¸€ä¸ªï¼Ÿå°åˆ°0.2ã€‚
æˆ‘ä»¬è¿˜æµ‹è¯•äº†æˆ‘ä»¬çš„åŸºç¡€è¿­ä»£ç¨å¾®å¤æ‚çš„æ•Œå¯¹æ”»å‡»æ¨¡å‹
æ–¹æ³•ï¼ˆKurakin et alã€‚ï¼ˆ2016ï¼‰ï¼‰ï¼Œè¿™åªæ˜¯ä¸Šè¿°æ”»å‡»ï¼Œé™¤äº†å®ƒéœ€è¦å¤šæ¬¡
åˆ›å»ºæ•Œå¯¹å›¾ç‰‡æ—¶æ­¥å¹…è¾ƒå°ã€‚æˆ‘ä»¬ä¹Ÿå‘ç°æˆ‘ä»¬çš„æ¨¡å‹æ›´å¤š
æ¯”ä¼ ç»Ÿçš„å·ç§¯æ¨¡å‹æ›´èƒ½æŠµå¾¡æ”»å‡»ã€‚

![å›¾3](https://github.com/humor250/matrixcapsules/blob/master/pic3_matrixcapsules.png)

Figure 3: Accuracy against  after an adversarial attack (left) and Success Rate after a targeted
adversarial attack (right). The targeted attack results were evaluated by averaging the success rate
after the attack for each of the 5 possible classes.
å›¾3ï¼šå¯¹æŠ—æ”»å‡»ï¼ˆå·¦ï¼‰åçš„$\epsilon$å‡†ç¡®æ€§å’Œç›®æ ‡æ”»å‡»ï¼ˆå³ï¼‰åçš„æˆåŠŸç‡ã€‚ç›®æ ‡æ”»å‡»ç»“æœï¼Œæ˜¯å¯¹5ä¸ªå¯èƒ½ç§ç±»çš„æ¯ä¸€ä¸ªçš„æ”»å‡»åï¼Œé€šè¿‡å¹³å‡æˆåŠŸç‡è¿›è¡Œè¯„ä¼°ã€‚

It has been shown that some robustness to adversarial attacks in models can be due to simple numerical
instability in the calculation of the gradient Brendel & Bethge (2017). To ensure that this
was not the sole cause of our modelâ€™s robustness, we calculated the percentage of zero values in the
gradient with respect to the image in the capsule model and found it to be smaller than that of the
CNN. Furthermore, the capsule gradients, although smaller that those of the CNN, are only smaller
by 2 orders of magnitude, as opposed to 16 orders of magnitude seen in Brendel & Bethge (2017)â€™s
work.
Finally we tested our modelâ€™s robustness to black box attacks by generating adversarial examples
with a CNN and testing them on both our capsule model and a different CNN. We found that the
capsule model did not perform noticeably better at this task than the CNN.

å·²ç»è¡¨æ˜ï¼Œæ¨¡å‹ä¸­å¯¹æŠ—æ”»å‡»çš„ä¸€äº›é²æ£’æ€§å¯èƒ½å½’å› äºç®€å•çš„æ•°å€¼
è®¡ç®—æ¢¯åº¦Brendelï¼†Bethgeï¼ˆ2017ï¼‰çš„ä¸ç¨³å®šæ€§ã€‚ä¸ºäº†ç¡®ä¿è¿™ä¸€ç‚¹
å¹¶ä¸æ˜¯æˆ‘ä»¬æ¨¡å‹ç¨³å¥æ€§çš„å”¯ä¸€åŸå› ï¼Œæˆ‘ä»¬è®¡ç®—äº†é›¶å€¼çš„ç™¾åˆ†æ¯”
ç›¸å¯¹äºèƒ¶å›Šæ¨¡å‹ä¸­çš„å›¾åƒçš„æ¢¯åº¦ï¼Œå¹¶ä¸”å‘ç°å…¶å°äº
CNNã€‚æ­¤å¤–ï¼Œèƒ¶å›Šæ¢¯åº¦è™½ç„¶å°äºCNNï¼Œä½†åªæœ‰è¾ƒå°çš„æ¢¯åº¦
å¢åŠ 2ä¸ªæ•°é‡çº§ï¼Œè€ŒBrendelï¼†Bethgeï¼ˆ2017ï¼‰çš„æ•°æ®åˆ™ä¸º16ä¸ªæ•°é‡çº§
å·¥ä½œã€‚
æœ€åï¼Œæˆ‘ä»¬é€šè¿‡ç”Ÿæˆæ•Œå¯¹çš„ä¾‹å­æ¥æµ‹è¯•æˆ‘ä»¬çš„æ¨¡å‹å¯¹é»‘åŒ£å­æ”»å‡»çš„é²æ£’æ€§
ä¸CNNå¹¶åœ¨æˆ‘ä»¬çš„èƒ¶å›Šæ¨¡å‹å’Œä¸åŒçš„CNNä¸Šæµ‹è¯•å®ƒä»¬ã€‚æˆ‘ä»¬å‘ç°äº†
èƒ¶å›Šæ¨¡å‹åœ¨è¿™é¡¹ä»»åŠ¡ä¸Šçš„è¡¨ç°å¹¶ä¸æ¯”CNNå¥½å¾—å¤šã€‚

7 RELATED WORK
Among the multiple recent attempts at improving the ability of neural networks to deal with viewpoint
variations, there are two main streams. One stream attempts to achieve viewpoint invariance
and the other aims for viewpoint equivariance. The work presented by Jaderberg et al. (2015)), Spatial
Transformer Networks, seeks viewpoint invariance by changing the sampling of CNNs according
to a selection of affine transformations. De Brabandere et al. (2016) extends spatial transformer
networks where the filters are adapted during inference depending on the input. They generate different
filters for each locality in the feature map rather than applying the same transformation to all
filters. Their approach is a step toward input covariance detection from traditional pattern matching
frameworks like standard CNNs (LeCun et al. (1990)). Dai et al. (2017) improves upon spatial
transformer networks by generalizing the sampling method of filters. Our work differs substantially
in that a unit is not activated based on the matching score with a filter (either fixed or dynamically
changing during inference). In our case, a capsule is activated only if the transformed poses coming
from the layer below match each other. This is a more effective way to capture covariance and leads
to models with many fewer parameters that generalize better.
The success of CNNs has motivated many researchers to extend the translational equivariance built
in to CNNs to include rotational equivariance (Cohen & Welling (2016), Dieleman et al. (2016),
Oyallon & Mallat (2015)). The recent approach in Harmonic Networks (Worrall et al. (2017))
achieves rotation equivariant feature maps by using circular harmonic filters and returning both the
maximal response and orientation using complex numbers. This shares the basic representational
idea of capsules: By assuming that there is only one instance of the entity at a location, we can
use several different numbers to represent its properties. They use a fixed number of streams of
rotation orders. By enforcing the equality of the sum of rotation orders along any path, they achieve
patch-wise rotation equivariance. This approach is more parameter-efficient than data augmentation
approaches, duplicating feature maps, or duplicating filters (Fasel & Gatica-Perez (2006), Laptev
et al. (2016)). Our approach encodes general viewpoint equivariance rather than only affine 2D
rotations. Symmetry networks (Gens & Domingos (2014)) use iterative Lucas-Kanade optimization
to find poses that are supported by the most low-level features. Their key weakness is that the
iterative algorithm always starts at the same pose, rather than the mean of the bottom-up votes.

Lenc & Vedaldi (2016) proposes a feature detection mechanism (DetNet) that is equivariant to affine
transformations. DetNet is designed to detect the same points in the image under different viewpoint
variations. This effort is orthogonal to our work but DetNet might be a good way to implement the
de-rendering first-stage that activates the layer of primary capsules.
Our routing algorithm can be seen as an attention mechanism. In this view, it is related to the work of
Gregor et al. (2015), where they improved the decoder performance in a generative model by using
Gaussian kernels to attend to different parts of the feature map generated by the encoder. Vaswani
et al. (2017) uses a softmax attention mechanism to match parts of the query sequence to parts of
the input sequence for the translation task and when generating an encoding for the query. They
show improvement upon previous translation efforts using recurrent architectures. Our algorithm
has attention in the opposite direction. The competition is not between the lower-level capsules that
a higher-level capsule might attend to. It is between the higher-level capsules that a lower-level
capsule might send its vote to.

7ç›¸å…³å·¥ä½œ
æœ€è¿‘å¤šæ¬¡å°è¯•æé«˜ç¥ç»ç½‘ç»œå¤„ç†è§†ç‚¹çš„èƒ½åŠ›
å˜åŒ–ï¼Œæœ‰ä¸¤ä¸ªä¸»è¦æµã€‚ä¸€ä¸ªæµå°è¯•å®ç°è§†ç‚¹ä¸å˜æ€§
å¦ä¸€ä¸ªç›®æ ‡æ˜¯è§†ç‚¹ç­‰åŒæ€§ã€‚ Jaderbergç­‰äººæå‡ºçš„å·¥ä½œã€‚ ï¼ˆ2015ï¼‰ï¼‰ï¼ŒSpatial
å˜å‹å™¨ç½‘ç»œé€šè¿‡æ”¹å˜CNNçš„é‡‡æ ·æ¥å¯»æ±‚è§†ç‚¹ä¸å˜æ€§
åˆ°é€‰æ‹©ä»¿å°„å˜æ¢ã€‚ De Brabandereç­‰äººã€‚ ï¼ˆ2016å¹´ï¼‰æ‰©å±•äº†ç©ºé—´å˜å‹å™¨
æ ¹æ®è¾“å…¥æ¨ç†è¿‡æ»¤å™¨çš„ç½‘ç»œã€‚ä»–ä»¬äº§ç”Ÿä¸åŒçš„
ä¸ºç‰¹å¾æ˜ å°„ä¸­çš„æ¯ä¸ªä½ç½®è¿‡æ»¤ï¼Œè€Œä¸æ˜¯å¯¹æ‰€æœ‰ä½ç½®åº”ç”¨ç›¸åŒçš„è½¬æ¢
è¿‡æ»¤å™¨ã€‚ä»–ä»¬çš„æ–¹æ³•æ˜¯ä»ä¼ ç»Ÿæ¨¡å¼åŒ¹é…å‘è¾“å…¥åæ–¹å·®æ£€æµ‹è¿ˆå‡ºçš„ä¸€æ­¥
åƒæ ‡å‡†CNNè¿™æ ·çš„æ¡†æ¶ï¼ˆLeCun et alã€‚ï¼ˆ1990ï¼‰ï¼‰ã€‚ Dai et alã€‚ ï¼ˆ2017å¹´ï¼‰æ”¹å–„ç©ºé—´
å˜å‹å™¨ç½‘ç»œé€šè¿‡æ¨å¹¿æ»¤æ³¢å™¨çš„æŠ½æ ·æ–¹æ³•ã€‚æˆ‘ä»¬çš„å·¥ä½œå·®åˆ«å¾ˆå¤§
å› ä¸ºæ ¹æ®è¿‡æ»¤å™¨çš„åŒ¹é…åˆ†æ•°ï¼ˆå›ºå®šæˆ–åŠ¨æ€ï¼‰ï¼Œå•ä½ä¸ä¼šè¢«æ¿€æ´»
åœ¨æ¨æ–­æœŸé—´æ”¹å˜ï¼‰ã€‚åœ¨æˆ‘ä»¬çš„ä¾‹å­ä¸­ï¼Œåªæœ‰åœ¨è½¬æ¢åçš„å§¿åŠ¿åˆ°æ¥æ—¶æ‰ä¼šæ¿€æ´»èƒ¶å›Š
ä»ä¸‹é¢çš„å›¾å±‚äº’ç›¸åŒ¹é…ã€‚è¿™æ˜¯æ•è·åæ–¹å·®å’Œçº¿ç´¢çš„æ›´æœ‰æ•ˆæ–¹æ³•
åˆ°å…·æœ‰æ›´å°‘æ³›åŒ–å‚æ•°çš„æ¨¡å‹æ›´å¥½ã€‚
CNNçš„æˆåŠŸä¿ƒä½¿è®¸å¤šç ”ç©¶äººå‘˜æ‰©å±•äº†æ‰€å»ºç«‹çš„å¹³ç§»ç­‰ä»·æ€§
åŒ…æ‹¬æ—‹è½¬ç­‰å˜é‡ï¼ˆCohenï¼†Wellingï¼ˆ2016ï¼‰ï¼ŒDielemanç­‰ï¼ˆ2016ï¼‰ï¼Œ
Oyallonï¼†Mallatï¼ˆ2015ï¼‰ï¼‰ã€‚ Harmonic Networksæœ€è¿‘çš„åšæ³•ï¼ˆWorrall et alã€‚ï¼ˆ2017ï¼‰ï¼‰
é€šè¿‡ä½¿ç”¨åœ†è°æ³¢æ»¤æ³¢å™¨å®ç°æ—‹è½¬ç­‰å˜ç‰¹å¾æ˜ å°„å¹¶è¿”å›ä¸¤è€…
æœ€å¤§å“åº”å’Œä½¿ç”¨å¤æ•°çš„æ–¹å‘ã€‚è¿™å…±äº«åŸºæœ¬ä»£è¡¨æ€§
èƒ¶å›Šçš„æƒ³æ³•ï¼šé€šè¿‡å‡è®¾ä¸€ä¸ªä½ç½®åªæœ‰ä¸€ä¸ªå®ä½“å®ä¾‹ï¼Œæˆ‘ä»¬å¯ä»¥
ä½¿ç”¨å‡ ä¸ªä¸åŒçš„æ•°å­—æ¥è¡¨ç¤ºå®ƒçš„å±æ€§ã€‚ä»–ä»¬ä½¿ç”¨å›ºå®šæ•°é‡çš„æµ
è½®æ¢è®¢å•ã€‚é€šè¿‡æ²¿ç€ä»»ä½•è·¯å¾„æ‰§è¡Œè½®æ¢é¡ºåºæ€»å’Œçš„ç­‰å¼ï¼Œå®ƒä»¬å¯ä»¥å®ç°
è¡¥ä¸å¼æ—‹è½¬ç­‰å˜æ€§ã€‚è¿™ç§æ–¹æ³•æ¯”æ•°æ®å¢å¼ºæ›´å…·å‚æ•°æ•ˆç‡
æ–¹æ³•ï¼Œå¤åˆ¶ç‰¹å¾åœ°å›¾æˆ–å¤åˆ¶è¿‡æ»¤å™¨ï¼ˆFaselï¼†Gatica-Perezï¼ˆ2006ï¼‰ï¼ŒLaptev
ç­‰äººã€‚ ï¼ˆ2016ï¼‰ï¼‰ã€‚æˆ‘ä»¬çš„æ–¹æ³•ç¼–ç ä¸€èˆ¬è§†ç‚¹ç­‰å˜é‡è€Œä¸æ˜¯ä»…ä»¿å°„äºŒç»´
æ—‹è½¬ã€‚å¯¹ç§°ç½‘ç»œï¼ˆGensï¼†Domingosï¼ˆ2014ï¼‰ï¼‰ä½¿ç”¨è¿­ä»£Lucas-Kanadeä¼˜åŒ–
æ‰¾åˆ°æœ€ä½çº§åˆ«åŠŸèƒ½æ”¯æŒçš„å§¿åŠ¿ã€‚ä»–ä»¬çš„å…³é”®å¼±ç‚¹æ˜¯ï¼Œ
è¿­ä»£ç®—æ³•å§‹ç»ˆå§‹äºç›¸åŒçš„å§¿åŠ¿ï¼Œè€Œä¸æ˜¯è‡ªä¸‹è€Œä¸Šçš„æŠ•ç¥¨çš„æ„æ€ã€‚

Lencå’ŒVedaldiï¼ˆ2016ï¼‰æå‡ºäº†ä¸€ä¸ªä¸ä»¿å°„ç­‰åŒçš„ç‰¹å¾æ£€æµ‹æœºåˆ¶ï¼ˆDetNetï¼‰
TRANSF


7.1 PREVIOUS WORK ON CAPSULES
Hinton et al. (2011) used a transformation matrix in a transforming autoencoder that learned to
transform a stereo pair of images into a stereo pair from a slightly different viewpoint. However,
that system requires the transformation matrix to be supplied externally. More recently, routing-byagreement
was shown to be effective for segmenting highly overlapping digits (Sabour et al. (2017)),
but that system has several deficiencies that we have overcome in this paper:
1. It uses the length of the pose vector to represent the probability that the entity represented by
a capsule is present. To keep the length less than 1, requires an unprincipled non-linearity
and this prevents the existence of any sensible objective function that is minimized by the
iterative routing procedure.
2. It uses the cosine of the angle between two pose vectors to measure their agreement. Unlike
the negative log variance of a Gaussian cluster, the cosine saturates at 1, which makes it
insensitive to the difference between a quite good agreement and a very good agreement.
3. It uses a vector of length n rather than a matrix with n elements to represent a pose, so its
transformation matrices have n
2 parameters rather than just n.

7.1ä»¥å‰çš„èƒ¶å›Šå·¥ä½œ
Hintonç­‰äººï¼ˆ2011ï¼‰åœ¨å­¦ä¹ è¿‡çš„å˜æ¢è‡ªç¼–ç å™¨ä¸­ä½¿ç”¨äº†å˜æ¢çŸ©é˜µ
å°†ä¸€å¯¹ç«‹ä½“å›¾åƒä»ç•¥å¾®ä¸åŒçš„è§†ç‚¹è½¬æ¢ä¸ºç«‹ä½“å¯¹ã€‚ç„¶è€Œï¼Œ
è¯¥ç³»ç»Ÿéœ€è¦ä»å¤–éƒ¨æä¾›å˜æ¢çŸ©é˜µã€‚æœ€è¿‘ï¼Œè·¯ç”± - é€šè¿‡åè®®
è¢«è¯æ˜å¯¹åˆ†å‰²é«˜åº¦é‡å çš„æ•°å­—æ˜¯æœ‰æ•ˆçš„ï¼ˆSabourç­‰ï¼ˆ2017ï¼‰ï¼‰ï¼Œ
ä½†æ˜¯è¿™ä¸ªç³»ç»Ÿæœ‰å‡ ä¸ªç¼ºé™·ï¼Œæˆ‘ä»¬åœ¨æœ¬æ–‡ä¸­å·²ç»è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼š
å®ƒä½¿ç”¨å§¿æ€å‘é‡çš„é•¿åº¦æ¥è¡¨ç¤ºç”±å®ä½“è¡¨ç¤ºçš„å®ä½“çš„æ¦‚ç‡
å­˜åœ¨èƒ¶å›Šã€‚è¦ä¿æŒé•¿åº¦å°äº1ï¼Œéœ€è¦ä¸€ä¸ªæ— åŸåˆ™çš„éçº¿æ€§
å¹¶ä¸”è¿™å¯ä»¥é˜²æ­¢ä»»ä½•ç”±æ­¤æœ€å°åŒ–çš„æ˜æ™ºçš„ç›®æ ‡å‡½æ•°çš„å­˜åœ¨
è¿­ä»£è·¯ç”±è¿‡ç¨‹ã€‚
å®ƒä½¿ç”¨ä¸¤ä¸ªå§¿æ€çŸ¢é‡ä¹‹é—´è§’åº¦çš„ä½™å¼¦æ¥è¡¡é‡å®ƒä»¬çš„ä¸€è‡´æ€§ã€‚ä¸åƒ
é«˜æ–¯ç°‡çš„è´Ÿå¯¹æ•°æ–¹å·®ï¼Œä½™å¼¦åœ¨1å¤„é¥±å’Œï¼Œè¿™ä½¿å¾—å®ƒ
å¯¹ç›¸å½“å¥½çš„åè®®å’Œéå¸¸å¥½çš„åè®®ä¹‹é—´çš„åŒºåˆ«ä¸æ•æ„Ÿã€‚
å®ƒä½¿ç”¨ä¸€ä¸ªé•¿åº¦ä¸ºnçš„çŸ¢é‡ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæœ‰nä¸ªå…ƒç´ çš„çŸ©é˜µæ¥è¡¨ç¤ºä¸€ä¸ªå§¿åŠ¿ï¼Œæ‰€ä»¥å®ƒæ˜¯
å˜æ¢çŸ©é˜µæœ‰nä¸ª
2ä¸ªå‚æ•°è€Œä¸ä»…ä»…æ˜¯nã€‚

8 CONCLUSION
Building on the work of Sabour et al. (2017), we have proposed a new type of capsule system in
which each capsule has a logistic unit to represent the presence of an entity and a 4x4 pose matrix
to represent the pose of that entity. We also introduced a new iterative routing procedure between
capsule layers, based on the EM algorithm, which allows the output of each lower-level capsule
to be routed to a capsule in the layer above in such a way that active capsules receive a cluster of
similar pose votes. This new system achieves significantly better accuracy on the smallNORB data
set than the state-of-the-art CNN, reducing the number of errors by 45%. We have also shown it to
be significantly more robust to white box adversarial attacks than a baseline CNN.
SmallNORB is an ideal data-set for developing new shape-recognition models precisely because it
lacks many of the additional features of images in the wild. Now that our capsules model works
well on NORB, we plan to implement an efficient version to test much larger models on much larger
data-sets such as ImageNet.
ACKNOWLEDGMENTS Thanks to Robert Gens, Eric Langlois, Taco Cohen and anonymous
commentators for helpful discussions and to everyone who made TensorFlow.

8ç»“è®º
ä»¥Sabourç­‰äººçš„å·¥ä½œä¸ºåŸºç¡€ã€‚ ï¼ˆ2017å¹´ï¼‰ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ–°å‹èƒ¶å›Šç³»ç»Ÿ
å…¶ä¸­æ¯ä¸ªèƒ¶å›Šå…·æœ‰ç”¨äºè¡¨ç¤ºå®ä½“å’Œ4Ã—4å§¿æ€çŸ©é˜µçš„å­˜åœ¨çš„é€»è¾‘å•å…ƒ
ä»¥è¡¨ç¤ºè¯¥å®ä½“çš„å§¿æ€ã€‚æˆ‘ä»¬è¿˜ä»‹ç»äº†ä¸€ç§æ–°çš„è¿­ä»£è·¯ç”±ç¨‹åº
åŸºäºEMç®—æ³•çš„èƒ¶å›Šå±‚ï¼Œå…¶å…è®¸æ¯ä¸ªè¾ƒä½çº§åˆ«èƒ¶å›Šçš„è¾“å‡º
è¢«è·¯ç”±åˆ°ä¸Šé¢çš„å±‚ä¸­çš„èƒ¶å›Šï¼Œä½¿å¾—æ´»æ€§èƒ¶å›Šæ¥æ”¶ä¸€ç°‡
ç±»ä¼¼çš„å§¿åŠ¿æŠ•ç¥¨ã€‚è¿™ä¸ªæ–°ç³»ç»Ÿåœ¨smallNORBæ•°æ®ä¸Šå®ç°äº†æ›´é«˜çš„ç²¾åº¦
æ¯”æœ€å…ˆè¿›çš„CNNè®¾ç½®ï¼Œå‡å°‘äº†45ï¼…çš„é”™è¯¯æ•°é‡ã€‚æˆ‘ä»¬ä¹Ÿå±•ç¤ºäº†å®ƒ
å¯¹äºç™½ç›’å¯¹æŠ—æ€§æ”»å‡»æ¯”åŸºçº¿CNNæ›´å¼ºå¤§ã€‚
SmallNORBæ˜¯å¼€å‘æ–°å‹å½¢çŠ¶è¯†åˆ«æ¨¡å‹çš„ç†æƒ³æ•°æ®é›†ï¼Œå› ä¸ºå®ƒæ°æ°æ˜¯
ç¼ºä¹é‡å¤–å›¾åƒçš„è®¸å¤šé™„åŠ åŠŸèƒ½ã€‚ç°åœ¨æˆ‘ä»¬çš„èƒ¶å›Šæ¨¡å‹èµ·ä½œç”¨äº†
åœ¨NORBä¸Šï¼Œæˆ‘ä»¬è®¡åˆ’å®æ–½ä¸€ä¸ªé«˜æ•ˆçš„ç‰ˆæœ¬æ¥æµ‹è¯•æ›´å¤§çš„æ¨¡å‹
æ•°æ®é›†å¦‚ImageNetã€‚
è‡´è°¢æ„Ÿè°¢Robert Gensï¼ŒEric Langloisï¼ŒTaco Cohenå’ŒåŒ¿å
æœ‰å¸®åŠ©çš„è®¨è®ºè¯„è®ºå‘˜å’Œæ¯ä¸ªåˆ¶ä½œTensorFlowçš„äººã€‚
